\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb, amsfonts, mathtools, tikz-cd, float}
\usepackage[left=2.5cm,right=2.5cm]{geometry}
\usepackage[shortlabels]{enumitem}
\usepackage{cancel}

\newcommand{\Int}{\mathrm{Int}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\pd}{\partial}
\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\hat}{\widehat}
\renewcommand{\tilde}{\widetilde}
\newcommand{\supp}{\mathrm{supp}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}[section]

\newtheorem{definition}{Definition}

\pagestyle{myheadings}

\begin{document}

\section{Lie Derivatives, Lie Algebras, and Frobenius' Theorem (July 10)}

(This lecture was pushed a day forward as the instructor could not make the usual lecture time on Thursday.)

\subsection{Equivalent Conditions for Zero Lie Derivative }

Suppose $X, Y \in \mathfrak{X}(M)$, and let $F$ denote the flow of $X$. Suppose $\mathcal{L}_XY$ is identically zero on $M$. Define a $C^\infty$ curve $H : \mathcal{D}^{(p)} \to T_pM$ by
\[
H : t \mapsto (F_{-t})_{*, F_t(p)}(Y_{F_t(p)}).
\]
Since $H$ is a smooth curve in a vector space, we can identify its derivative with an element of the vector space $T_pM$. We have
\begin{align*}
H'(t_0) &= \left. \frac{d}{dt} \right|_{t = t_0} (F_{-t})_{*, F_t(p)}(Y_{F_t(p)}) \\
&= \left. \frac{d}{dt} \right|_{t = t_0} (F_{-(t - t_0) - t_0})_{*, F_{t - t_0 + t_0}(p)}(Y_{F_{t - t_0 + t_0}(p)}) \\
&= \left. \frac{d}{dt} \right|_{t = 0} (F_{-t - t_0})_{*, F_{t + t_0}(p)}(Y_{F_{t + t_0}(p)}) \\
&= \left. \frac{d}{dt} \right|_{t = 0} (F_{t_0} \circ F_{-t})_{*,F_t(F_{t_0}(p))} (Y_{F_t(F_{t_0}(p))}) \\
&= \left. \frac{d}{dt} \right|_{t = 0}  (F_{t_0})_{*,F_{t_0}(p)} \left( (F_{-t})_{*,F_t(F_{t_0}(p))}(Y_{F_t(F_{t_0}(p))}) \right) \\
&= (F_{t_0})_{*,F_{t_0}(p)} \left. \frac{d}{dt} \right|_{t = 0}    (F_{-t})_{*,F_t(F_{t_0}(p))}(Y_{F_t(F_{t_0}(p))})  \\
&= (F_{t_0})_{*,F_{t_0}(p)} (\mathcal{L}_XY)_{F_{t_0}(p)} \\
&= 0.
\end{align*}
So $H$ is constant. Therefore $H(t) = Y_p$ for all $t \in \mathcal{D}^{(p)}$. Applying $(F_t)_{*, p}$ to both sides gives
\[
Y_{F_t(p)} = (F_t)_{*,p} (Y_p) \text{ for all } t \in \mathcal{D}^{(p)}.
\]
When this condition is satisfied, we say that $Y$ is \emph{invariant under the flow of $X$}. We have just shown the following proposition.

\begin{proposition}
If $\mathcal{L}_XY$ is identically zero on $M$, then $Y$ is invariant under the flow of $X$.
\end{proposition}
We will eventually show that the hypothesis $\mathcal{L}_XY \equiv 0$ also implies that $X$ is invariant under the flow of $Y$, which will be a corollary of the identity $\mathcal{L}_XY = - \mathcal{L}_YX$.

One way to imagine this situation is through curves. Suppose $\gamma(s)$ is a $C^\infty$ curve in $M$ starting at $p$ with $\gamma'(0) = Y_p$. Suppose the conclusion of the above proposition is satisfied. We have
\begin{align*}
(F_t \circ \gamma)'(0) = (F_t)_{*,p}(\gamma'(0)) = (F_t)_{*,p}(Y_p) = Y_{F_t(p)},
\end{align*}
the last step following from the previous proposition. In particular, choose $\gamma$ to be the unique integral curve of $Y$ starting at $p$. Then, for all $s$ at which $\gamma$ is defined,
\[
(F_t \circ \gamma)'(s) = (F_t)_{*,\gamma(s)}(\gamma'(s)) = (F_t)_{*,p}(Y_{\gamma(s)}) = Y_{(F_t \circ \gamma)(s)},
\]
the last step again following from the previous proposition. We have proven the following proposition.

\begin{proposition}
If $Y$ is invariant under the flow $F$ of $X$, then for each $t$, $F_t$ takes integral curves of $Y$ to integral curves of $Y$.
\end{proposition}

Now suppose the conclusion of this proposition holds. Let $F$ be the flow of $X \in \mathfrak{X}(M)$ and $G$ the flow of $Y \in \mathfrak{X}(M)$. Assume for simplicity that the vector fields are complete. Fix $p \in M$. For a fixed $t_0$, this conclusion implies that $F_{t_0}(G_s(p))$ is the integral curve of $Y$ starting at $F_{t_0}(p)$. But then $F_{t_0}(G_s(p)) = G_s(F_{t_0}(p))$ for all $s$ for which it makes sense. Since $t_0$ and $p$ were arbitrary, we have $F_t \circ G_s = G_s \circ F_t$ for all $s,t$ for which it makes sense. We say, in this case, that the flows of $X$ and $Y$ \emph{commute}. We have proven the following proposition.

\begin{proposition}
If $X$ and $Y$ are complete and if the flow of $X$ takes integral curves of $Y$ to integral curves of $Y$, then the flows of $X$ and $Y$ commute.
\end{proposition}

Note that each proposition implies the next one. It turns out that they are actually equivalent, which we now state and prove. The theorem holds without the assumption that $X$ and $Y$ are complete.

\begin{theorem}
(Equivalent conditions for zero Lie derivative, complete case) Let $X, Y \in \mathfrak{X}(M)$ be complete vector fields. The following are equivalent:
\begin{enumerate}
\item $\mathcal{L}_XY \equiv 0$.
\item $Y$ is invariant under the flow of $X$.
\item The flow of $X$ takes integral curves of $Y$ to integral curves of $Y$.
\item The flows of $X$ and $Y$ commute.
\end{enumerate}
\end{theorem}
\begin{proof}
We have shown that (1) $\implies$ (2) $\implies$ (3) $\implies$ (4). All we need to prove is that (4) implies (1), which is very easy. Let $F$ denote the flow of $X$ and $G$ the flow of $Y$. Given $p \in M$, we have
\[
F_t(G_s(p)) = G_s(F_t(p))
\]
for all $t,s$. Differentiating with respect to $s$ at $0$ gives
\[
(F_t)_{*,p}(Y_p) = Y_{F_t(p)},
\]
implying
\[
Y_p = (F_{-t})_{*,F_t(p)}(Y_{F_t(p)}).
\]
Since this holds for all $t$, $(\mathcal{L}_XY)_p = 0$. Since $p$ was arbitrary, $\mathcal{L}_XY \equiv 0$.
\end{proof}
Note that the fourth condition in the theorem is symmetric in $X$ and $Y$. Therefore all of the conditions of the theorem hold when $X$ and $Y$ are switched: in particular, $\mathcal{L}_XY \equiv 0$ if and only if $\mathcal{L}_YX \equiv 0$.

\subsection{A Formula for the Lie Derivative}

We will now derive a very simple formula for the Lie derivative. Given $X, Y \in \mathfrak{X}(M)$, let $F$ be the flow of $X$. Fix $p \in M$ and consider $H : \mathcal{D}^{(p)} \to T_pM$ defined by 
\[
H : t \mapsto (F_{-t})_{*, F_t(p)}(Y_{F_t(p)}).
\]
Then $H$ is a smooth function into the vector space $T_pM$. We may therefore identify $H'(0)$ with an element of $T_pM$; that element is precisely $H'(0) = (\mathcal{L}_XY)_p$. Since $H$ takes elements in a vector space, we can look at its Taylor series expansion near $t = 0$:
\[
(F_{-t})_{*,F_t(p)}(Y_{F_t(p)}) = H(t) = H(0) + tH'(0) + o(t) = Y_p + t(\mathcal{L}_XY)_p + o(t).
\]
Applying $(F_t)_{*,p}$ to both sides and rearranging
\[
Y_{F_t(p)} - (F_t)_{*,p}(Y_p) = t (F_t)_{*,p}((\mathcal{L}_XY)_p) + o(t).
\]
Suppose $f \in C^\infty(M)$. Evaluating both sides at $f$ gives
\[
(Y(f) \circ F_t)(p) - (Y(f \circ F_t))(p) = t (\mathcal{L}_XY)((f \circ F_t))(p) + o(t).
\]
Note that $(Y(f) \circ F_t)(p)$ and $f \circ F_t$ are functions of $t$ into vector spaces, so we can look at their Taylor series expansions near $t = 0$:
\begin{alignat*}{2}
(Y(f) \circ F_t)(p) &= Y_p(f) + t \left. \frac{d}{dt} \right|_{t = 0} (Y(f) \circ F_t)(p) + o(t) &&= Y_p(f) + t X_p(Y(f)) + o(t) \\
f \circ F_t & &&= f + t X(f) + o(t).
\end{alignat*}
Substituting these back in gives us
\[
\bcancel{Y_p(f)} + tX_p(Y(f)) - (Y(\bcancel{f} + t X(f) + o(t)))(p) = t (\mathcal{L}_XY)((f + t X(f) + o(t)))(p) + o(t),
\]
(the backslashes indicate that those terms cancel out) simplifying to
\[
t \Big[ X_p(Y(f)) - Y_p(X(f)) \Big] = t (\mathcal{L}_XY)((f + t X(f) + o(t)))(p) + o(t).
\]
By linearity on the right side, we can take out the term $tX(f) + o(t)$ from the argument of $\mathcal{L}_XY$. This term will be absorbed into the rightmost $o(t)$. Thus
\[
t \Big[ X_p(Y(f)) - Y_p(X(f)) \Big] = t (\mathcal{L}_XY)_p(f) + o(t).
\]
Using the Lie bracket $[X,Y] := XY - YX$, this may be written as 
\[
t [X,Y]_p(f) = t(\mathcal{L}_XY)_p(f) + o(t).
\]
Dividing by $t$ and taking the limit $t \to 0$ gives us the following
\begin{theorem}
$\mathcal{L}_XY = [X,Y]$.
\end{theorem}
With this formula in hand, we may very easily compute Lie derivatives. Note that this implies $\mathcal{L}_XY = -\mathcal{L}_YX$. Also, with this, we can say that $X$ and $Y$ commute if $[X, Y] = 0$.

Note the following properties of the Lie bracket:
\begin{enumerate}
\item Bilinearity.
\item Anticommutativity.
\item The \emph{Jacobi identity} 
\[
\sum_{\text{cyclic}} [X, [Y,Z]] = 0,
\]
or equivalently
\[
[X, [Y,Z]] + [Y, [Z, X]] + [Z, [X,Y]] = 0.
\]
\end{enumerate}
All of these are relatively obvious from the definition. Note that every property of the Lie bracket implies a property of the Lie derivative (after all, they are the same). Note that the Lie bracket is \emph{not} in general associative; the Jacobi identity ruins any hope of associativity in general.

\subsection{Lie Algebras}

Let us abstract away from vector fields on manifolds and consider only the structure a vector space is given when we define on it a "product" holding properties similar to the Lie bracket.

\begin{definition}
A Lie algebra is a vector space $V$ over a field $F$ together with a bilinear, anticommutative operation $[\cdot, \cdot] : V \times V \to V$ which satisfies the Jacobi identity.
\end{definition}
Note that a Lie algebra is, in general, not an algebra. Recall that an \emph{algebra} is a vector space $V$ over a field equipped with a "product" $\cdot : V \times V \to V$ making $V$ into a ring (with or without identity) which satisfies a homogeneity condition with respect to the vector space's scalar multiplication. 

However, if $(V, \cdot)$ is an algebra, we can consider the ring commutator on $V$ with respect to $\cdot$:
\[
[v, w] := v \cdot w - w \cdot v.
\]
One easily checks that the operation defined above gives the algebra $V$ a Lie algebra structure.

The most familiar example of a Lie algebra to us is $\mathfrak{X}(M)$ with the Lie bracket $[X,Y] = XY - YX$. (Note that the "multiplication" $XY$ here is a vector field defined by $(XY)(f) = X(Y(f))$, viewing vector fields as derivations of $C^\infty(M)$.) There are three main algebraic structures at play here:
\begin{itemize}
\item A real vector space structure.
\item A $C^\infty(M)$-module structure
\item A real Lie algebra structure.
\end{itemize}

\begin{definition}
A derivation on a Lie algebra $V$ is a linear map $D : V \to V$ with respect to the vector space structure satisfying the Leibnitz rule
\[
D([X,Y]) = [D(X),Y] + [X, D(Y)].
\]
\end{definition}

The next proposition provides an important class of derivations, one special member of which we are very familiar with.

\begin{proposition}
For $X$ in a Lie algebra $V$, define $\mathrm{ad}_X : V \to V$ by $\mathrm{ad}_X(Y) = [X,Y]$. Then $\mathrm{ad}_X$ is a derivation on $V$.
\end{proposition}
\begin{proof}
Linearity of $\mathrm{ad}_X$ follows from bilinearity of $[\cdot, \cdot]$. The Jacobi identity may be written as
\[
[X,[Y,Z]] = [[X,Y],Z] + [Y,[X,Z]],
\]
or alternatively,
\[
\mathrm{ad}_X([Y,Z]) = [\mathrm{ad}_X(Y), Z] + [Y, \mathrm{ad}_X(Z)].
\]
\end{proof}
\begin{corollary}
For a fixed $X \in \mathfrak{X}(M)$, the map $\mathcal{L}_X : \mathfrak{X}(M) \to \mathfrak{X}(M)$ defined by $\mathcal{L}_X(Y) = \mathcal{L}_XY$ is a derivation of the Lie algebra $\mathfrak{X}(M)$.
\end{corollary}
Let us note some important properties of the Lie derivative, whose proofs are relatively straightforward computations.
\begin{proposition}
The Lie derivative satisfies
\begin{enumerate}[(i)]
\item $\mathcal{L}_XY = -\mathcal{L}_YX$.
\item $\mathcal{L}_X([Y,Z]) = [\mathcal{L}_XY, Z] + [Y, \mathcal{L}_XZ]$.
\item $\mathcal{L}_{[X,Y]}Z = \mathcal{L}_X(\mathcal{L}_YZ) - \mathcal{L}_Y(\mathcal{L}_XZ)$.
\item If $g \in C^\infty(M)$, $\mathcal{L}_X(gY) = g\mathcal{L}_XY + X(g) \cdot Y$.
\item If $F : M \to N$ is a diffeomorphism, $F_*(\mathcal{L}_XY) = \mathcal{L}_{F_*X}(F_*Y)$.
\end{enumerate}
\end{proposition}

%careful with those calculations in (iv)
\begin{proof}
(i) and (ii) are immediate. For (iii), the Jacobi identity may be written as
\[
[[X,Y], Z] = [X, [Y,Z]] - [Y, [X,Z]],
\]
which is the desired identity. For (iv), if $f \in C^\infty(M)$ then
\begin{align*}
(\mathcal{L}_X(gY))(f) &= X((gY)(f)) - (gY)(X(f)) \\
&= X(g \cdot Y(f)) - g \cdot Y(X(f)) \\
&= g \cdot X(Y(f)) + Y(f) \cdot X(g) - g \cdot Y(X(f)) \\
&= g (\mathcal{L}_XY)(f) - (X(g)Y)(f),
\end{align*}
so the identity holds. The last is left as an exercise (was not included in lecture).
\end{proof}

\subsection{Mini Frobenius' Theorem}

Suppose $X \in \mathfrak{X}(M)$. Given $p \in M$, we can think of finding the integral curve of $X$ starting at $p$ as finding a $1$-dimensional (immersed) submanifold of $M$ to which $X$ is everywhere tangent. If we increase to $k$ vector fields, when can we find $k$-dimensional submanifolds of $M$ to which those vector fields are everywhere tangent? Such questions lead us to Frobenius' theorem.

Let $(U, \phi) = (U, x^1, \dots, x^n)$ be a chart on $M$. Suppose $f \in C^\infty(M)$. Then the function $\frac{\pd f}{\pd x^i}$ is again a $C^\infty$ function on $M$, for each $i$. Equality of second-order mixed partials gives
\[
\frac{\pd^2 f}{\pd x^i \pd x^j} = \frac{\pd^2 f}{\pd x^j \pd x^i},
\]
implying that the Lie bracket
\[
\left[ \frac{\pd}{\pd x^i}, \frac{\pd}{\pd x^j} \right] = 0.
\]
That is, the coordinate vector fields commute. Is this condition also sufficient? That is, is the following statement true? 

"Suppose $X_1, \dots, X_k$ is a \emph{(smooth) $k$-frame}; a collection of $k$ smooth vector fields such that $(X_1)_p, \dots, (X_k)_p$ are linearly independent for all $p \in M$. Suppose $[X_i, X_j] = 0$ for each $1 \leq i, j \leq k$. Are $X_1, \dots, X_k$ coordinate vector fields? That is, for $p \in M$, does there exist a chart $(U, x^1, \dots, x^n)$ near $p$ such that
\[
\frac{\pd}{\pd x^i} = X_i \text{ for } 1 \leq i \leq k?"
\] 
(We do not require $k = n$.)

% why can we choose such an epsilon??
Suppose $X,Y$ is a smooth commuting $2$-frame on $M$. Let $p \in M$ and let $U$ be a neighbourhood of $p$ such that the flows $F$ of $X$ and $G$ of $Y$ are defined on some $(-\epsilon, \epsilon) \times U$. Define $A : (-\epsilon, \epsilon)^2 \to U$ by 
\[
A(s,t) = G_s(F_t(p)) = F_t(G_s(p)).
\]
(Equality holds since $[X,Y] = 0$.) $A$ is $C^\infty$, and
\begin{align*}
A_{*, (s_0, t_0} \left( \frac{\pd}{\pd s} \right) &= \left. \frac{\pd A}{\pd s} \right|_{(s_0, t_0)} = Y_{A(s_0, t_0)} \\
A_{*, (s_0, t_0} \left( \frac{\pd}{\pd s} \right) &= \left. \frac{\pd A}{\pd t} \right|_{(s_0, t_0)} = X_{A(s_0, t_0)}.
\end{align*}
The fact that $X,Y$ is a $2$-frame implies that $A$ is an immersion. By the immersion theorem there is a chart $(U, \phi) = (U, x^1, \dots, x^n)$ near $p$ such that
\begin{align*}
\phi \circ A : (-\epsilon', \epsilon')^2 &\to \R^n \\
(s,t) &\mapsto (s,t,0,\dots,0)
\end{align*}
for some $\epsilon' \in (0, \epsilon]$. Then
\begin{align*}
\frac{\pd}{\pd x^1} &= Y \\
\frac{\pd}{\pd x^2} &= X
\end{align*}
on $A((-\epsilon', \epsilon')^2)$. Since $A$ is an embedding on $(-\epsilon', \epsilon')^2$, $S = A((-\epsilon', \epsilon')^2)$ is a $2$-dimensional embedded submanifold of $M$ such that for every $q \in S$, $T_qS = \mathrm{span}(\{X_q,Y_q\})$, and for which $(U, \phi)$ is an adapted chart. Moreover, $X$ and $Y$ are coordinate vector fields with respect to the chart $\phi_S = \pi \circ S$ on $S$. In this case, we call $S$ an \emph{integral submanifold of the $2$-frame $X,Y$.} We have proven the following theorem:

\begin{theorem}
(Mini-Frobenius) Let $X_1, \dots, X_k$ be a smooth commuting $k$-frame on $M$. Let $p \in M$. There exists a $k$-dimensional integral submanifold $S$ of this frame which contains $p$. Also, there exists an adapted chart $(U, \phi)$ near $p$ relative to $S$ such that the coordinate vector fields relative to $\phi_S$ are
\[
\frac{\pd }{\pd x^i} = X_i \text{ for } 1 \leq i \leq k.
\]
\end{theorem}
(We may state the result for arbitrary $k$ since the only thing that changes in the proof is the notation.)

\subsection{Leading up to Frobenius' Theorem}

We will be able to weaken the hypotheses of the preceding theorem. We will replace "commuting" with "such that $[X_i, X_j] \in \mathrm{span}(\{X_1, \dots, X_k\})$".

Let $S$ be a $k$-dimensional submanifold of $M$ which is an integral submanifold for the $k$-frame $X_1, \dots, X_k$ (i.e. $T_qS = \mathrm{span}(\{ (X_1)_q, \dots, (X_k)_q \})$ for all $q \in S$). Then
\[
[X_i, Z_j] = \sum a_\ell X_\ell
\]
for some functions $a_\ell$. The proof is an exercise. (Hint: write in coordinates the Lie bracket.) This shows that if $X_p, Y_p \in T_pS$, then $[X,Y]_p \in S$. In particular, the condition stated in the previous paragraph is necessary; Frobenius' theorem tells us that it is sufficient.

Now let $X, Y$ be a $2$-frame. Let $(U, \phi)$ be a chart as before. Then 
\[
\frac{\pd}{\pd x^1} = Y \qquad \frac{\pd}{\pd x^2} = X
\]
on $S$. We chose $\phi$ so that the integral curves of $Y$ on $S$ are precisely the integral curves of $\pd / \pd x^1$, and similarly for $X$ and $\pd / \pd x^2$, since $\phi \circ A : (s,t) \mapsto (s,t,0,\dots,0)$. But we do not necessarily have this on all of $U$; we have still not shown that $X$ and $Y$ are coordinate vector fields on $U$. We shall remedy this.

Consider the map
\[
H : (s,t, x^3, \dots, x^n) \mapsto G_s(F_t(\phi^{-1}(0,0,x^3,\dots,x^n))).
\]

\begin{proposition}
Let $\psi$ be the inverse of $H$, defined above. Then $\psi$ is a coordinate chart whose first two coordinate vector fields are $Y$ and $X$, respectively.
\end{proposition}

We have a

\begin{theorem}
Let $X_1, \dots, X_k$ be a smooth commuting $k$-frame on $M$. Let $p \in M$. Then there exists a chart $(U, \phi)$ near $p$ such that 
\[
\frac{\pd}{\pd x^i} = X_i
\]
for $1 \leq i \leq k$. (What does this mean when $k = 1$?)
\end{theorem}

\begin{lemma}
(Lemma for Frobenius' theorem) If $X_1, \dots, X_k$ is a smooth $k$-frame such that $[X_i, X_j] \in \mathrm{span}(\{ X_1, \dots, X_k \})$, then there is a smooth commuting $k$-frame $Y_1, \dots, Y_k$ such that $\mathrm{span}(\{ X_1, \dots, X_k \}) = \mathrm{span}(\{ Y_1, \dots, Y_k \})$.
\end{lemma}

"Commuting" is a necessary and sufficient condition for the vector fields to be coordinate vector fields.

\end{document}
  

  